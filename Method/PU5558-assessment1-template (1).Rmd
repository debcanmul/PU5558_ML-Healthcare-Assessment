---
title: "PU5558-Machine Learning in Healthcare"
author: "Student ID - 52102609"
output: 
  pdf_document:
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, global_options, include=FALSE}
knitr::opts_chunk$set(message=FALSE, tidy.opts=list(width.cutoff=80), tidy=TRUE) 
```

***

## Introduction
The answers to the assessment questions are within the template sections, any additional work completed to help work out the answers can be found in the appendix. I have created a machine learning model for my answer to question 1.

***

## Load necessary packages

```{r All packages including those needed for the appendix}
library(tidyverse)    # for general data science
library(tidymodels)   # for machine learning
library(corrplot)     # for visualising correlation matrices
library(vip)          # for variable importance plots
library(randomForest) # for the random forest model engine
```

***
## Load chosen dataset

The data chosen for the machine learning task was the Knee Replacement data set. Information about the variables contained within the data set can be found in the document Patient Reported Outcome Measures in England Data Dictionary version 3.4.

```{r}
knee_data <- read_csv("Knee Replacement CCG 2021 (2).csv")

glimpse(knee_data) #provides a general overview of the data


```
 

```{r selected columns and preprocessed data}
knee_data_col<-knee_data%>%
  select(`Pre-Op Q EQ5D Index`,`Age Band`,`Gender`,`Pre-Op Q EQ VAS`,`Knee Replacement Pre-Op Q Pain`:`Knee Replacement Pre-Op Q Score`,`Post-Op Q EQ5D Index`) %>% #These are the variables chosen from the available data source.Note all the variables from Knee Replacement Pre-Op Q Pain to Knee Replacement Pre-Op Q Score are included.
  drop_na() %>%    # remove rows with missing values
  unique()%>% # keep unique row
  filter(`Age Band`!="*")%>% # filter rows for Age Band is NOT "*"
filter (`Gender`!="*") # filter rows for Gender is NOT "*"

```

```{r Preview the changes to the data}

glimpse(knee_data_col) #provides a general overview of the processed data

```
Note: I was going to use age and gender as predictor variables, but randomForest wouldn't work for character variable, so I changed to factor but it still didn't work so I removed the variables age and gender from the recipe. This step could have been completed within the recipe. I have left the code to change the variables from character to factor.

For the data set description please go to line 69.
```{r check variable type}
class("Age Band") # This checks what type of variable of Age Band. It can also be seen in the summary above as <chr> character.
```


```{r change Age Band to a factor variable}
knee_data_col$`Age Band` <-as.factor(knee_data_col$`Age Band`) # this selects the column Age Band within the named data set and changes the column to a factor variable.
 
  
```

```{r change Gender to a factor variable}
knee_data_col$Gender<-as.factor(knee_data_col$Gender) # this selects the column Gender within the named data set and changes the column to a factor variable.
```

```{r preview of the prepared data}
glimpse(knee_data_col)
```
***

## Dataset description


This assessment will use the Knee Replacement CCG 2021 data set.
Note there are character (qualitative) and double (quantitative) variables within the data set. I chose variables that would be available before the operation. Only using the Post-Op EQ5D Index to train the model. There are 81 variables in the original data set, I selected 18 from the 81 variables. 

The data set containing the 18 variables was then tidied to remove any rows with missing values. Only unique rows were kept. Finally, only rows in the Age Band and Gender without * were kept. 

I then changed the Age Band and Gender variables from characters to factors, but these variables weren't used to train the model.

### Chosen potential predictor variables:

Reference to PROMS and briefly explain the variables

* Pre-Op EQ5D Index
This is a value calculated before the operation. The EQ5D Index is a number ranging from -0.594 to 1. The lower the score the worse the patient reports. The number is generated from a combination of answers from 5 topics; mobility, self care, usual activities, pain and discomfort and anxiety and depression.

* Age Band

* Gender

* Pre-Op Q EQ VAS
The EQ VAS score is a number between 0 and 100. The lower the number the worse health the patient. 

* Knee Replacement Pre-Op Q Pain...consecutive variables to... Knee Replacement Pre-Op Q Score

### Outcome Variable
* Post-Op Q EQ5D Index 
This calculated the same way as in the Pre-Op EQ5D Index but the questions are asked after the knee replacement.

***

## Suitable machine learning algorithm for three questions:

When choosing a model there are many factors to consider; types and availability of data, sample size, accuracy of the model, time available to train and develop and the interpretability of the model. The sample size is much greater than 50 so no addiModel type, mode and engine.

**1. Before the operation, can we estimate the post-operative EQ5D index for a patient?**

The type of machine learning will be supervised learning. This is because we have data for the outcome variable of interest to train the algorithm, Post-Op Q EQ5D. The output variable is a numerical continuous variable, rounded to 3 decimal places. Whether the outcome variable is numerical or categorical determines the type of supervised learning algorithm. Regression is used when the outcome variable is numeric. There are various types of regression algorithms that can be selected for this problem. ref It is usually best to select the simplest algorithm that can solve the problem rather than an overly complicated algorithm which only provides a small increase in accuracy. ref  

If there is a linear relationship between the outcome variables and the predictors then you can use linear regression.  See flowchart which ML. Linear regression, Random Forest - state can be used for both. On analysis the outcome variable is skewed to the right. If skewed data was used in the linear regression it could result in an error in the estimated confidence intervals of the feature weights values. ref It would be recommended to transform the outcome variable, see Appendix 1. However, random forest doesn't require transformation of the outcome variable. ref Random forest is the algorithm chosen to answer this question.



**2. Before the operation, can we predict how much pain a patient will have after the operation?**

This question can also be solved by using supervised learning. We have data for the outcome variable, Post-Op Q Pain. This variable has discrete answers 0-4 and each of the values represents a category. Therefore the type of algorithm will be classification. There are different classification algorithms that could be chosen for this problem. ref 

Logistic regression would not be suitable for this problem because the algorithm requires binary output. In this case there would be 5 categories. Support Vector Machine (SVM) is an algorithm suitable for classification supervised learning. Specifically it would be radial basis function support vector machines. This uses a non-linear hyperplane of the data for categorisation.



**3. Before the operation, can we calculate how many patients have had previous surgery?** 

I believe that this question doesn't require a machine learning algorithm to answer the question. The variable "Pre-Op Q Previous Surgery" could be used to calculate this answer by filtering for unique values and then counting the number of participants who have data value "1", which represents YES.

***

## Model building to answer chosen question

**1.	Data splitting**
overfitting??

The data is split into a test set and a training set. The training set is used to train the machine algorithm. The test set is only used at the very end of the machine learning process and is used only once. 

The proportion of the split really depends on the context of the question. If the training data is too small it reduces the probability of finding accurate parameter estimates (coefficients). The coefficients are measured as the change in outcome variable for 1 unit change in a predictor, with all other predictors remaining the same. If the test data is too small it will provide poor estimates of the performance. For this machine learning problem I have proportioned the training set to contain 80% of the filtered data set and the test data will contain 20% of the filtered data set. 

```{r data splitting}

knee_data_split <- knee_data_col %>%
    initial_split(prop = 0.8, 
                  strata = `Post-Op Q EQ5D Index`) # 0.8 states the proportion of the training set. Strata ensures that the distribution of the variables in Post-Op Q EQ5D Index variable matches both the training and data set. The distribution is skewed to the right as shown in appendix 1.

knee_train <- training(knee_data_split) #this is the training data
knee_test <- testing(knee_data_split) #this is the test data

```

**2.	Selection and preprocessing of predictors**

A recipe consists of a formula and the data to be used in the machine learning model. The formula is used to specify the outcome variable and predictors. The data undergoes any preprocessing. The recipe includes a combination of any necessary preprocessing steps on the training data before training the model begins. There are different types of preprocessing steps, some examples include transformation of the outcome variable to a more normal distribution, changing qualitative variables to dummy variables and extracting raw data from a variable i.e. a day of the week from a date variable. 

```{r selection and preprocessing}

simple_rec <- knee_train %>% #we are gong to use the training data
  recipe(`Post-Op Q EQ5D Index`~`Pre-Op Q EQ5D Index`+`Pre-Op Q EQ VAS`+`Knee Replacement Pre-Op Q Pain`+`Knee Replacement Pre-Op Q Score`) %>% # The outcome variable is, Post-Op Q EQ5D and all of the variables to the right of the tilda are the chosen predictors.
  step_zv(all_predictors()) %>% # this step removes any single values
  step_corr(all_predictors()) # this step removes large absolute corrections
```

**3.	Model specification and training**

The random forest model can either be in regression or classification mode. Nodes and trees....see CN supervised linear regression

```{r model specification}
# Random forest model specification: rf_spec
rf_spec <- rand_forest() %>%
    set_mode("regression") %>% # select regression as mode
    set_engine("randomForest") # select randomForest for the engine
```

The workflow combines the model specification with the recipe. Different recipes are often needed for different models. It is useful to combine models and recipes because it is easier to train and test workflows. 


```{r workflow}

knee_wflow_rf <-workflow() %>%
           add_recipe(simple_rec) %>% # adds the recipe created earlier to the workflow
           add_model(rf_spec) # adds the model specification
```

The model is now ready to be trained using the workflow and the training data set.


```{r train-model}

knee_wflow_fit <- knee_wflow_rf %>% #the workflow is selected
    fit(data = knee_train) # the training data is used to train the random forest algorithm

```

The trained workflow can now be assessed to determine which of the predictors is most important when predicting the outcome variable.

```{r view predictors in order of importance}
knee_wflow_fit %>% 
  extract_fit_parsnip() %>% # this extracts the data
  vip(num_features = 4) # provides an output showing the predictor values in order of importance.
```
It can be seen in the diagram above that the Pre-Op Q EQ5D Index is the most important variable when calculating the outcome variable.


***

**4.	Model evaluation**

The test data can now be used to assess the random forest model. The success of the prediction is assessed using metrics. The metrics calculated for this regression model are the root mean square error (rmse), R squared (rsq), and the mean absolute error (mae). The root mean square error is used for continuous numerical variables. The difference between each predicted and the actual value are squared. The mean is found for all the squared differences and then the square root is taken. If you have a small RMSE then the actual values and predicted values are close. 

R squared (rsq) is also known as the Coefficient of Determination. The closer to 1 the more the change in the outcome variable can be explained by the predictor. 

```{r eval-testing-data}


predicted_EQ5D_test <- knee_wflow_fit %>% #create a new object for the test using the fitted model
  predict(new_data = knee_test) #use the test data for prediction


results_test <- knee_test %>% #create a new object called results_test
  bind_cols(predicted_EQ5D_test) %>% #add the new predicted column to the data set
  rename(pred_EQ5D = .pred)   # rename the predicted column


metrics(results_test, truth = `Post-Op Q EQ5D Index`, estimate = pred_EQ5D) # calculate the success of the prediction

```
The RMSE is 0.2261745 this is fairly low and suggests the model fits reasonably well. However, the rsq value suggests there is weak correlation.



```{r}
glimpse(results_test)
```

The predicted values and the actual values can now be plotted on a scatter graph.

```{r plot-model-prediction}

results_test %>%
  ggplot(aes(x = `Post-Op Q EQ5D Index`, y = pred_EQ5D)) + # the known outcome variable values and the predicted values are selected
  geom_abline(intercept=0, slope=1) +  # this plots a line going through the origin and with an angle of 45 degrees to the x-axis, we want out points to be as close as possible to the line
  geom_point() + 
  xlab("actual outcome values") + 
  ylab("predicted outcome values")

```
You can see from the scatter graph above there are considerable amount of data points to the left of the diagonal line. This model would require further work to improve the success of the predictions.



***

## Limitations of machine learning model

Variation and Bias
Random forest models may have high variance in comparison to 

Choose difference variables


Understanding of casual limits
resampling

PCA ?? - see CN section

Blackbox - loss of interpretability - link https://www.listendata.com/2014/11/random-forest-with-r.html
Hyperparameters for random forest
I iltered the original data source to remove missing values for age and gender. I didn't use age or gender for the machine learning so the extra data removed reduced the training set for the chosen predictors.
Random Forest - factors and dummy variables
Further investigation would be required.

***

## Appendix 1 - Linear Regression
I initially decided to try linear regression as a model.  There may be confounding variable, factors that affect the Post-Op EQ5D Index other than those chosen, but due to lack of understanding of the research area I have simply chosen variables that are likely to have a relationship.

```{r display outcome variable data in a histogram}
knee_data_col %>%
ggplot(aes(x = `Post-Op Q EQ5D Index`)) + 
  geom_histogram(bins = 30, col= "white")
```

The variable we are trying to predict is not a normal distribution so we would have to transform the data. I used the log10() scale added to the histogram, but it didn't seem to transform the graph to a normal distribution. There are other types of transforming that could be used.

```{r transform data and plot on histogram}
knee_data_col %>%
ggplot(aes(x = `Post-Op Q EQ5D Index`)) + 
  geom_histogram(bins = 30, col= "white")+ scale_x_log10()
```

The potential predictors can be checked for correlation using the corrplot function as shown below. The reduced number of variables make the corrplot easier to read. If all 81 variables had been included in the corrplot it wouldn't have been legible. It would have been good practice to try different selection of variables and check for correlation.

Notice Age Band and Gender are not in the corrplot. This is because these variables are still characters and not numeric. The variables will be changed to numeric in the workflow.

```{r}
knee_data_cor <- cor(knee_train %>% select_if(is.numeric))
corrplot(knee_data_cor, tl.cex = 0.5)
```

It can be seen in the corrplot that there aren't any strong linear relationships between Post-Op Q EQ5D and the other variables. I checked three of the predictor variables against the outcome variable in separate scatterplots.


```{r check for linear relationship 1}
knee_train %>%
  ggplot(aes(x =`Pre-Op Q EQ5D Index`, y = `Post-Op Q EQ5D Index`)) + 
  geom_point()
```



```{r check for linear relationship 2}
knee_train %>%
  ggplot(aes(x = `Knee Replacement Pre-Op Q Work`, y = `Post-Op Q EQ5D Index`)) + 
  geom_point()
```


```{r check for linear relationship 3}
knee_train %>%
  ggplot(aes(x = `Knee Replacement Pre-Op Q Score`, y = `Post-Op Q EQ5D Index`)) + 
  geom_point()
```

There was no linearity shown in the 3 graphs. I then decided to compare the linear regression with random forest, see appendix 2.

***

## Appendix 2 Comparison of Linear Regression and Random Forest

```{r}

# Linear regression model specification: lm_spec
lm_spec <- linear_reg() 

# Random forest model specification: rf_spec
rf_spec <- rand_forest() %>%
    set_mode("regression") %>%
    set_engine("randomForest")

```

**Workflow**

And two different workflows:

```{r specify-workflow}

# Linear model workflow: DZ_wflow_lm
knee_wflow_lm <-workflow() %>%
           add_recipe(simple_rec) %>%
           add_model(lm_spec)

# Random forest workflow: DZ_wflow_rf
knee_wflow_rf <-workflow() %>%
           add_recipe(simple_rec) %>%
           add_model(rf_spec)

```

```{r cross-validation}

knee_folds <- vfold_cv(knee_train, v = 10) # 10-fold cross validation

# We want to save the predictions
keep_pred <- control_resamples(save_pred = TRUE)

# Fit the two model:

# Linear regression (make sure you named the workflow DZ_wflow_lm)
knee_wflow_lm_fit <- knee_wflow_lm %>%
    fit_resamples(resamples = knee_folds, 
                  control = keep_pred)

# Random forest (make sure you named the workflow DZ_wflow_rf)
knee_wflow_rf_fit <- knee_wflow_rf %>%
    fit_resamples(resamples = knee_folds, 
                  control = keep_pred)
    
```




```{r cross-val-performance}

bind_rows(collect_metrics(knee_wflow_lm_fit) %>%
                          mutate(model = "linear_regression"),
          collect_metrics(knee_wflow_rf_fit) %>%
                          mutate(model = "random_forest"))

```




```{r cross-val-plot}

results <-  bind_rows(knee_wflow_lm_fit %>%
                          collect_predictions() %>%
                          mutate(model = "linear_regression") %>%
                          rename(pred_PostEQ5D = .pred),
                      knee_wflow_rf_fit %>%
                          collect_predictions() %>%
                          mutate(model = "random_forest") %>%
                          rename(pred_PostEQ5D = .pred))

results %>%
    ggplot(aes(x = `Post-Op Q EQ5D Index`, y = pred_PostEQ5D)) +
    geom_abline(intercept=0, slope=1) +  # we want data to fall close to this line
    geom_point() +
    facet_wrap(~ model)

```


```{r final-fit}

# Fit the two models (make sure you named the data split object DZ_split)

knee_wflow_lm_finalfit <- knee_wflow_lm %>%
    last_fit(knee_data_split)

knee_wflow_rf_finalfit <- knee_wflow_rf %>%
    last_fit(knee_data_split)

# Print performance metrics on testing data
bind_rows(collect_metrics(knee_wflow_lm_finalfit) %>%
                          mutate(model = "linear_regression"),
          collect_metrics(knee_wflow_rf_finalfit) %>%
                          mutate(model = "random_forest"))

```



